{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNn39GVe+J7JFUch9DDjsyR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c504feac51d47f289a9ba19a0b9a501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c59fe238a6f4431192acc401d894df9e",
              "IPY_MODEL_f1b42b276fdc437ab078ec51d9aa0bc8",
              "IPY_MODEL_05ba05419e734c23ad1efe2eabd5f999"
            ],
            "layout": "IPY_MODEL_9a10ba194a444e409c3377a8b876dd3e"
          }
        },
        "c59fe238a6f4431192acc401d894df9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2590dfe76daf41c4932b0bc0edb1e481",
            "placeholder": "​",
            "style": "IPY_MODEL_0c1aac8e05874331a854f3a5c17b11a3",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "f1b42b276fdc437ab078ec51d9aa0bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2e32f8055d04ce4a8bfc5d08aadea53",
            "max": 511193709,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_994782b9c1c2470e8cb620857221bb51",
            "value": 511193709
          }
        },
        "05ba05419e734c23ad1efe2eabd5f999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_612e5c4c968c4914b35b2d94cdd25d03",
            "placeholder": "​",
            "style": "IPY_MODEL_0aa9a3e366c148f4aa0c2bb54ef75d42",
            "value": " 511M/511M [00:12&lt;00:00, 56.7MB/s]"
          }
        },
        "9a10ba194a444e409c3377a8b876dd3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2590dfe76daf41c4932b0bc0edb1e481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c1aac8e05874331a854f3a5c17b11a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2e32f8055d04ce4a8bfc5d08aadea53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "994782b9c1c2470e8cb620857221bb51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "612e5c4c968c4914b35b2d94cdd25d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aa9a3e366c148f4aa0c2bb54ef75d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/520817/gp/blob/main/adhd(ner%20%EB%AA%A8%EB%8D%B8%20%EC%B5%9C%EC%A2%85).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-3wuU86tE65c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "np.random.seed(42)\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "hHiShMlYFe58"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3IXkvipR0mh",
        "outputId": "1cb21cfc-7014-4274-8a2f-103b08d3b525"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PL2JL6a_FfuX",
        "outputId": "67c7d9f6-09a4-4df9-b2cc-11a1792feae2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kmounlp/NER.git"
      ],
      "metadata": {
        "id": "MSGy3bujF0I3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b009099-f54b-4721-dfb3-ad2fb95592b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'NER' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "x-T8lhgCNs-B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list=[]"
      ],
      "metadata": {
        "id": "NglrP3LLNu1B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in os.walk('NER/'):\n",
        "  for y in glob.glob(os.path.join(x[0], '*_NER.txt')):\n",
        "    file_list.append(y)"
      ],
      "metadata": {
        "id": "CO6Qof1eNxLs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = sorted(file_list)"
      ],
      "metadata": {
        "id": "e9mgRtR0N6CZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "file_path = file_list[0]\n",
        "file_path = Path(file_path)\n",
        "raw_text = file_path.read_text().strip()"
      ],
      "metadata": {
        "id": "ATeQEDq5OB0A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install korpora\n",
        "\n",
        "from Korpora import Korpora\n",
        "corpus = Korpora.load(\"naver_changwon_ner\")"
      ],
      "metadata": {
        "id": "5rXoICJNO83V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2685b5ac-9728-4885-b241-c9f17ae44e68"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: korpora in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.10/dist-packages (from korpora) (0.6)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from korpora) (1.25.2)\n",
            "Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from korpora) (4.66.2)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from korpora) (2.31.0)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from korpora) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->korpora) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->korpora) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->korpora) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->korpora) (2024.2.2)\n",
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : 네이버 + 창원대\n",
            "    Repository : https://github.com/naver/nlp-challenge/tree/master/missions/ner\n",
            "    References : http://air.changwon.ac.kr/?page_id=10\n",
            "\n",
            "    개체명(Named Entity)은 인명, 기관명, 지명 등과 같이 문장 또는 문서에서 특정한 의미를 가지고 있는 단어 또는 어구를 말합니다.\n",
            "    이 때문에 개체명은 정보 검색 및 언어 이해를 위한 분석에서 주요한 대상으로 다루어지고 있습니다.\n",
            "    Data.ly에서는 개체명 코퍼스를 제공하여 연구에 도움을 드리고자 하며, 공개적인 리더보드를 통해 많은 분들의 연구 동향을 논의/공유하고자 합니다.\n",
            "    제공되는 코퍼스는 Data.ly에서 제작한 것으로, 연구 및 리더보드를 위한 학습으로 사용 가능하며 상업적인 목적으로 사용될 수 없습니다.\n",
            "\n",
            "    # License\n",
            "    연구 및 리더보드를 위한 학습으로 사용 가능하며 상업적인 목적으로 사용될 수 없습니다.\n",
            "\n",
            "[Korpora] Corpus `naver_changwon_ner` is already installed at /root/Korpora/naver_changwon_ner/train_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "네이버 데이터셋 전처리"
      ],
      "metadata": {
        "id": "9k8XkJDkrT3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naver_read_file(file_list):\n",
        "\n",
        "    token_docs = []\n",
        "    tag_docs = []\n",
        "\n",
        "    for doc in file_list:\n",
        "        tokens = []\n",
        "        tags = []\n",
        "        list1=doc.words\n",
        "        list2=doc.tags\n",
        "\n",
        "        for text,tag in zip(list1,list2):\n",
        "            for i, syllable in enumerate(text): # 음절 단위로 자르고\n",
        "                tokens.append(syllable)\n",
        "                if tag == '-':\n",
        "                  tag = 'O' # 태그가 '-'인 경우 'O'로 변경\n",
        "                tags.append(tag)\n",
        "\n",
        "        token_docs.append(tokens)\n",
        "        tag_docs.append(tags)\n",
        "\n",
        "    return token_docs, tag_docs"
      ],
      "metadata": {
        "id": "0jp7_bpxPYvb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naver_text,naver_tags =naver_read_file(corpus.train)"
      ],
      "metadata": {
        "id": "THjYXlx8e024"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(naver_text))\n",
        "print(len(naver_tags))"
      ],
      "metadata": {
        "id": "5V1r7hKMe06z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9eac23-763f-48e1-80cd-4b457109c0b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90000\n",
            "90000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(naver_text[0], end='\\n\\n') # 음절 단위로 잘 잘렸네요!\n",
        "print(naver_tags[0])"
      ],
      "metadata": {
        "id": "q9-iJwb1nNNM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f927ae-2435-4ba5-b536-752a16b2944d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['비', '토', '리', '오', '양', '일', '만', '에', '영', '사', '관', '감', '호', '용', '퇴', ',', '항', '룡', '압', '력', '설', '의', '심', '만', '가', '율']\n",
            "\n",
            "['PER_B', 'PER_B', 'PER_B', 'PER_B', 'DAT_B', 'DAT_B', 'O', 'O', 'ORG_B', 'ORG_B', 'ORG_B', 'CVL_B', 'CVL_B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "해양 뭐시기 데이터셋 전처리"
      ],
      "metadata": {
        "id": "_4L-7mfvrZEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def read_file(file_list):\n",
        "    token_docs = []\n",
        "    tag_docs = []\n",
        "    for file_path in file_list:\n",
        "        #print(\"read file from \", file_path)\n",
        "        file_path = Path(file_path)\n",
        "        raw_text = file_path.read_text().strip()\n",
        "        raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
        "\n",
        "        for doc in raw_docs:\n",
        "            tokens = []\n",
        "            tags = []\n",
        "            for line in doc.split('\\n'):\n",
        "                if line[0:1] == \"$\" or line[0:1] == \";\" or line[0:2] == \"##\":\n",
        "                    continue\n",
        "                token = line.split('\\t')[0]\n",
        "                tag = line.split('\\t')[3]\n",
        "                for i, syllable in enumerate(token):    # 음절 단위로 잘라서\n",
        "                    tokens.append(syllable)\n",
        "                    tags.append(tag)\n",
        "\n",
        "            token_docs.append(tokens)\n",
        "            tag_docs.append(tags)\n",
        "\n",
        "    return token_docs, tag_docs"
      ],
      "metadata": {
        "id": "xOSLg1QNrfvS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts, tags = read_file(file_list[:])"
      ],
      "metadata": {
        "id": "o724eldkrNL0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(texts))\n",
        "print(len(tags))"
      ],
      "metadata": {
        "id": "fA1kWKcKtcCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ff40b1-e734-4709-b22e-4b6136fef5d3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19263\n",
            "19263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[0], end='\\n\\n') # 음절 단위로 잘 잘렸네요!\n",
        "print(tags[0])"
      ],
      "metadata": {
        "id": "VDlObStTtcMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1bd1066-3f0e-484d-8e69-554023774ab2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['오', '에', '_', '겐', '자', '부', '로', '는', '_', '일', '본', '_', '현', '대', '문', '학', '의', '_', '초', '석', '을', '_', '놓', '은', '_', '것', '으', '로', '_', '평', '가', '받', '는', '_', '작', '가', '_', '나', '쓰', '메', '_', '소', '세', '키', '(', '1', '8', '6', '7', '~', '1', '9', '1', '6', ')', '의', '_', '대', '표', '작', '_', '‘', '마', '음', '’', '에', '_', '담', '긴', '_', '군', '국', '주', '의', '적', '_', '요', '소', ',', '_', '야', '스', '쿠', '니', '_', '신', '사', '_', '참', '배', '_', '행', '위', '까', '지', '_', '소', '설', '의', '_', '삽', '화', '로', '_', '동', '원', '하', '며', '_', '일', '본', '_', '사', '회', '의', '_', '‘', '비', '정', '상', '성', '’', '을', '_', '문', '제', '_', '삼', '는', '다', '.']\n",
            "\n",
            "['B-PER', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'O', 'B-LOC', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'B-DUR', 'B-DUR', 'B-DUR', 'B-DUR', 'I-DUR', 'I-DUR', 'I-DUR', 'I-DUR', 'I-DUR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-POH', 'B-POH', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'B-ORG', 'B-ORG', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "분리된 토큰을 하나의 개체명으로 묶어 주는 태깅 시스템을 위해 있는게 BIO, BIESO임.\n",
        "\n",
        "여러 개의 토큰으로 이루어진 개체명의 경우\n",
        "\n",
        "**개체명이 시작할 때** 'B,begin'\n",
        "\n",
        "**토큰이 개체명 중간에 있을 때** 'I,inside'\n",
        "\n",
        "**개체명의 마지막에 위치할 때** 'E,end'\n",
        "\n",
        "**하나의 토큰이 곧 하나의 개체명일 때** 'S,singleton'\n",
        "\n",
        "**토큰이 개체명이 아닐 경우** 'O,outside'"
      ],
      "metadata": {
        "id": "8w7_-eiNbz5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tags = set(tag for doc in tags for tag in doc)\n",
        "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
        "id2tag = {id: tag for tag, id in tag2id.items()}\n",
        "\n",
        "for i, tag in enumerate(unique_tags):\n",
        "    print(tag)  #해양 tags 변경 전"
      ],
      "metadata": {
        "id": "SF0eRYxDkqwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff491c44-08c7-4cb8-a06d-49dc4f948b95"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I-ORG\n",
            "B-PNT\n",
            "B-DUR\n",
            "I-PNT\n",
            "I-MNY\n",
            "I-PER\n",
            "B-DAT\n",
            "O\n",
            "B-PER\n",
            "I-NOH\n",
            "B-NOH\n",
            "B-LOC\n",
            "I-TIM\n",
            "B-MNY\n",
            "I-DAT\n",
            "B-TIM\n",
            "I-DUR\n",
            "I-POH\n",
            "B-ORG\n",
            "B-POH\n",
            "I-LOC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sublist in tags:\n",
        "    for i, label in enumerate(sublist):\n",
        "        if label == 'I-NOH':\n",
        "            sublist[i] = 'NOH_I'\n",
        "        elif label == 'I-PNT':\n",
        "            sublist[i] = 'PNT_I'\n",
        "        elif label == 'I-ORG':\n",
        "            sublist[i] = 'ORG_I'\n",
        "        elif label == 'I-DUR':\n",
        "            sublist[i] = 'DUR_I'\n",
        "        elif label == 'I-TIM':\n",
        "            sublist[i] = 'TIM_I'\n",
        "        elif label == 'I-PER':\n",
        "            sublist[i] = 'PER_I'\n",
        "        elif label == 'I-MNY':\n",
        "            sublist[i] = 'MNY_I'\n",
        "        elif label == 'B-MNY':\n",
        "            sublist[i] = 'MNY_B'\n",
        "        elif label == 'B-DAY':\n",
        "            sublist[i] = 'DAY_B'\n",
        "        elif label == 'B-TIM':\n",
        "            sublist[i] = 'TIM_B'\n",
        "        elif label == 'I-LOC':\n",
        "            sublist[i] = 'LOC_I'\n",
        "        elif label == 'B-PER':\n",
        "            sublist[i] = 'PER_B'\n",
        "        elif label == 'B-ORG':\n",
        "            sublist[i] = 'ORG_B'\n",
        "        elif label == 'B-LOC':\n",
        "            sublist[i] = 'LOC_B'\n",
        "        elif label == 'B-PNT':\n",
        "            sublist[i] = 'PNT_B'\n",
        "        elif label == 'B-NOH':\n",
        "            sublist[i] = 'NOH_B'\n",
        "        elif label == 'I-PER':\n",
        "            sublist[i] = 'PER_I'\n",
        "        elif label == 'B-LOC':\n",
        "            sublist[i] = 'LOC_B'\n",
        "        elif label == 'I-POH':\n",
        "            sublist[i] = 'POH_I'\n",
        "        elif label == 'I-DAT':\n",
        "            sublist[i] = 'DAT_I'\n",
        "        elif label == 'B-POH':\n",
        "            sublist[i] = 'POH_B'\n",
        "        elif label == 'B-DUR':\n",
        "            sublist[i] = 'DUR_B'\n",
        "        elif label == 'B-DAT':\n",
        "            sublist[i] = 'DAT_B'\n",
        "        elif label == '0':\n",
        "            sublist[i] = '0'"
      ],
      "metadata": {
        "id": "pw1se6PFj5sT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tags = set(tag for doc in tags for tag in doc)\n",
        "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
        "id2tag = {id: tag for tag, id in tag2id.items()}\n",
        "\n",
        "for i, tag in enumerate(unique_tags):\n",
        "    print(tag)  #해양 tags 변경 후"
      ],
      "metadata": {
        "id": "h7bFUznW56C_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df32b649-0098-4bd7-9d6e-b4385c161deb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POH_B\n",
            "TIM_I\n",
            "PER_I\n",
            "POH_I\n",
            "TIM_B\n",
            "O\n",
            "DAT_I\n",
            "DUR_I\n",
            "PNT_B\n",
            "PNT_I\n",
            "MNY_I\n",
            "ORG_I\n",
            "MNY_B\n",
            "ORG_B\n",
            "LOC_B\n",
            "DAT_B\n",
            "DUR_B\n",
            "PER_B\n",
            "LOC_I\n",
            "NOH_B\n",
            "NOH_I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts.extend(naver_text)\n",
        "tags.extend(naver_tags)"
      ],
      "metadata": {
        "id": "0o94hYy66Fvt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tags = set(tag for doc in tags for tag in doc)\n",
        "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
        "id2tag = {id: tag for tag, id in tag2id.items()}"
      ],
      "metadata": {
        "id": "VHE_IE4O6jui"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, tag in enumerate(unique_tags):\n",
        "    print(tag)  # 학습을 위한 label list를 확인합니다."
      ],
      "metadata": {
        "id": "zKpiYcZE6lW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "287db7c2-dd43-4bff-eb7c-dafc1f9aed47"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POH_B\n",
            "CVL_B\n",
            "FLD_B\n",
            "FLD_I\n",
            "EVT_I\n",
            "AFW_B\n",
            "CVL_I\n",
            "NUM_B\n",
            "MAT_I\n",
            "TIM_I\n",
            "ANM_I\n",
            "PER_I\n",
            "POH_I\n",
            "TRM_I\n",
            "TIM_B\n",
            "ANM_B\n",
            "O\n",
            "DAT_I\n",
            "DUR_I\n",
            "PNT_B\n",
            "PNT_I\n",
            "MNY_I\n",
            "EVT_B\n",
            "ORG_I\n",
            "MNY_B\n",
            "ORG_B\n",
            "LOC_B\n",
            "PLT_I\n",
            "MAT_B\n",
            "DAT_B\n",
            "NUM_I\n",
            "AFW_I\n",
            "PLT_B\n",
            "DUR_B\n",
            "PER_B\n",
            "LOC_I\n",
            "NOH_B\n",
            "TRM_B\n",
            "NOH_I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tag in list(tag2id.keys()) :\n",
        "    globals()[tag] = 0\n",
        "\n",
        "for tag in tags :\n",
        "    for ner in tag :\n",
        "        globals()[ner] += 1\n",
        "\n",
        "for tag in list(tag2id.keys()) :\n",
        "    print('{:>6} : {:>7,}'. format(tag, globals()[tag]))"
      ],
      "metadata": {
        "id": "dZKSVM847DXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db41ccd5-e485-40ab-97d0-81c3cffe7fca"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " POH_B :  18,025\n",
            " CVL_B : 266,517\n",
            " FLD_B :   9,715\n",
            " FLD_I :     155\n",
            " EVT_I :  31,340\n",
            " AFW_B :  23,535\n",
            " CVL_I :  15,293\n",
            " NUM_B : 228,990\n",
            " MAT_I :      62\n",
            " TIM_I :   5,195\n",
            " ANM_I :     172\n",
            " PER_I :  32,070\n",
            " POH_I :  25,817\n",
            " TRM_I :  14,924\n",
            " TIM_B :  11,147\n",
            " ANM_B :  22,070\n",
            "     O : 3,067,701\n",
            " DAT_I :  29,419\n",
            " DUR_I :   3,549\n",
            " PNT_B :   4,430\n",
            " PNT_I :   1,855\n",
            " MNY_I :   4,929\n",
            " EVT_B :  59,714\n",
            " ORG_I :  45,175\n",
            " MNY_B :   3,441\n",
            " ORG_B : 279,040\n",
            " LOC_B : 108,316\n",
            " PLT_I :       5\n",
            " MAT_B :   1,001\n",
            " DAT_B :  90,643\n",
            " NUM_I :  26,913\n",
            " AFW_I :   9,433\n",
            " PLT_B :     952\n",
            " DUR_B :   2,231\n",
            " PER_B : 213,186\n",
            " LOC_I :   7,656\n",
            " NOH_B :  18,839\n",
            " TRM_B : 129,695\n",
            " NOH_I :  16,179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, test_texts, train_tags, test_tags = train_test_split(texts, tags, test_size=.2, random_state=42)"
      ],
      "metadata": {
        "id": "SDN7pFeX7ht2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train 문장 : {:>6,}' .format(len(train_texts)))\n",
        "print('Train 태그 : {:>6,}' .format(len(train_tags)))\n",
        "print('Test  문장 : {:>6,}' .format(len(test_texts)))\n",
        "print('Test  태그 : {:>6,}' .format(len(test_tags)))"
      ],
      "metadata": {
        "id": "q-YH9ZnT7hx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1beb100e-0e4e-44e2-810f-cc1703a38c66"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 문장 : 87,410\n",
            "Train 태그 : 87,410\n",
            "Test  문장 : 21,853\n",
            "Test  태그 : 21,853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts[5]"
      ],
      "metadata": {
        "id": "TZOGxTHa7h1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e1cf40-ae8d-4bbc-efe7-c9c9050bbf79"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['첫',\n",
              " '출',\n",
              " '발',\n",
              " '남',\n",
              " '상',\n",
              " '은',\n",
              " '작',\n",
              " '은',\n",
              " '어',\n",
              " '간',\n",
              " '하',\n",
              " '나',\n",
              " '였',\n",
              " '어',\n",
              " '요',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT 토크나이저"
      ],
      "metadata": {
        "id": "rrTVAmV57umZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
        "MODEL_NAME = \"beomi/KcELECTRA-base-v2022\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "HWlZUwuB7h5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc9517d-2d36-45be-d257-b29586abc0ac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tags = set(tag for doc in tags for tag in doc)\n",
        "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
        "id2tag = {id: tag for tag, id in tag2id.items()}"
      ],
      "metadata": {
        "id": "LgYgUvlX7z4a"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_token_id = tokenizer.pad_token_id # 0\n",
        "cls_token_id = tokenizer.cls_token_id # 101\n",
        "sep_token_id = tokenizer.sep_token_id # 102\n",
        "pad_token_label_id = tag2id['O']    # tag2id['O']\n",
        "cls_token_label_id = tag2id['O']\n",
        "sep_token_label_id = tag2id['O']"
      ],
      "metadata": {
        "id": "KyKDtxJK73Fc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ner_tokenizer(sent, max_seq_length):\n",
        "    pre_syllable = \"_\"\n",
        "    input_ids = [pad_token_id] * (max_seq_length - 1)\n",
        "    attention_mask = [0] * (max_seq_length - 1)\n",
        "    token_type_ids = [0] * max_seq_length\n",
        "    sent = sent[:max_seq_length-2]\n",
        "\n",
        "    for i, syllable in enumerate(sent):\n",
        "        if syllable == '_':\n",
        "            pre_syllable = syllable\n",
        "        if pre_syllable != \"_\":\n",
        "            syllable = '##' + syllable  # 중간 음절에는 모두 prefix를 붙입니다.\n",
        "            # 우리가 구성한 학습 데이터도 이렇게 구성되었기 때문이라고 함.\n",
        "            # 이순신은 조선 -> [이, ##순, ##신, ##은, 조, ##선]\n",
        "        pre_syllable = syllable\n",
        "\n",
        "        input_ids[i] = (tokenizer.convert_tokens_to_ids(syllable))\n",
        "        attention_mask[i] = 1\n",
        "\n",
        "    input_ids = [cls_token_id] + input_ids\n",
        "    input_ids[len(sent)+1] = sep_token_id\n",
        "    attention_mask = [1] + attention_mask\n",
        "    attention_mask[len(sent)+1] = 1\n",
        "    return {\"input_ids\":input_ids,\n",
        "            \"attention_mask\":attention_mask,\n",
        "            \"token_type_ids\":token_type_ids}"
      ],
      "metadata": {
        "id": "H56iODmK73I3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ner_tokenizer(train_texts[0], 5))"
      ],
      "metadata": {
        "id": "uNzD1LHq78Sx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c6d5ac-6457-4a6a-92ee-81082c35ef25"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [2, 1912, 4044, 4040, 3], 'attention_mask': [1, 1, 1, 1, 1], 'token_type_ids': [0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_sentences = []\n",
        "tokenized_test_sentences = []\n",
        "\n",
        "for text in train_texts:    # 전체 데이터를 tokenizing 합니다.\n",
        "    tokenized_train_sentences.append(ner_tokenizer(text, 128))\n",
        "for text in test_texts:\n",
        "    tokenized_test_sentences.append(ner_tokenizer(text, 128))"
      ],
      "metadata": {
        "id": "TvaNc5Nr78Xu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_tags(tags, max_seq_length):\n",
        "    # label 역시 입력 token과 개수를 맞춰줍니다\n",
        "    tags = tags[:max_seq_length-2]\n",
        "    labels = [tag2id[tag] for tag in tags]\n",
        "    labels = [tag2id['O']] + labels\n",
        "\n",
        "    padding_length = max_seq_length - len(labels)\n",
        "    labels = labels + ([pad_token_label_id] * padding_length)\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "VuyXg4Zo78bV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag2id"
      ],
      "metadata": {
        "id": "7jmQTT2X8B7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683edf18-aad7-47a1-f2da-c79350008874"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'POH_B': 0,\n",
              " 'CVL_B': 1,\n",
              " 'FLD_B': 2,\n",
              " 'FLD_I': 3,\n",
              " 'EVT_I': 4,\n",
              " 'AFW_B': 5,\n",
              " 'CVL_I': 6,\n",
              " 'NUM_B': 7,\n",
              " 'MAT_I': 8,\n",
              " 'TIM_I': 9,\n",
              " 'ANM_I': 10,\n",
              " 'PER_I': 11,\n",
              " 'POH_I': 12,\n",
              " 'TRM_I': 13,\n",
              " 'TIM_B': 14,\n",
              " 'ANM_B': 15,\n",
              " 'O': 16,\n",
              " 'DAT_I': 17,\n",
              " 'DUR_I': 18,\n",
              " 'PNT_B': 19,\n",
              " 'PNT_I': 20,\n",
              " 'MNY_I': 21,\n",
              " 'EVT_B': 22,\n",
              " 'ORG_I': 23,\n",
              " 'MNY_B': 24,\n",
              " 'ORG_B': 25,\n",
              " 'LOC_B': 26,\n",
              " 'PLT_I': 27,\n",
              " 'MAT_B': 28,\n",
              " 'DAT_B': 29,\n",
              " 'NUM_I': 30,\n",
              " 'AFW_I': 31,\n",
              " 'PLT_B': 32,\n",
              " 'DUR_B': 33,\n",
              " 'PER_B': 34,\n",
              " 'LOC_I': 35,\n",
              " 'NOH_B': 36,\n",
              " 'TRM_B': 37,\n",
              " 'NOH_I': 38}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encode_tags(train_tags[0], 5)"
      ],
      "metadata": {
        "id": "d2JC7k6e8CAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfea695-62e0-4abd-b5b8-faa720b8aacf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[16, 34, 34, 34, 16]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = []\n",
        "test_labels = []\n",
        "\n",
        "for tag in train_tags:\n",
        "    train_labels.append(encode_tags(tag, 128))\n",
        "\n",
        "for tag in test_tags:\n",
        "    test_labels.append(encode_tags(tag, 128))"
      ],
      "metadata": {
        "id": "G0u4iCxr8CEb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels), len(test_labels)"
      ],
      "metadata": {
        "id": "PzyG7_6v8CJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2842f40-875b-42e0-81f0-4ad2c0244ec4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87410, 21853)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token 데이터셋"
      ],
      "metadata": {
        "id": "UsmqYe7y8N92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class TokenDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val) for key, val in self.encodings[idx].items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = TokenDataset(tokenized_train_sentences, train_labels)\n",
        "test_dataset = TokenDataset(tokenized_test_sentences, test_labels)"
      ],
      "metadata": {
        "id": "9VO4H2NC8CNj"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers==4.30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtU_7rnlt9GE",
        "outputId": "66281763-345a-4ba2-b417-ec2744436d74"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.30 in /usr/local/lib/python3.10/dist-packages (4.30.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForTokenClassification, Trainer, TrainingArguments, AutoModelForTokenClassification,EarlyStoppingCallback\n",
        "import sys\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=5,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=1000, # 1000번쨰 steps마다 log를 보여줌\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=5,\n",
        "    save_strategy='steps', # steps로 해야 earlystop이 가능\n",
        "    evaluation_strategy='steps',\n",
        "    save_steps=1000, # 1000번쨰 step마다 저장\n",
        "    eval_steps=1000, # 1000번째 step마다 평가\n",
        "    seed=15,\n",
        "    load_best_model_at_end=True # 가장 좋은 성능의 모델로...\n",
        ")"
      ],
      "metadata": {
        "id": "tN6IMVxC8Q-T"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BertForTokenClassification"
      ],
      "metadata": {
        "id": "2REJe1Qdu_BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, num_labels=len(unique_tags))\n",
        "model.to(device)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,# evaluation dataset\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=2)] #loss가 2번 감소하지 않으면 스탑\n",
        ")"
      ],
      "metadata": {
        "id": "p_R6K6En8RCS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "3c504feac51d47f289a9ba19a0b9a501",
            "c59fe238a6f4431192acc401d894df9e",
            "f1b42b276fdc437ab078ec51d9aa0bc8",
            "05ba05419e734c23ad1efe2eabd5f999",
            "9a10ba194a444e409c3377a8b876dd3e",
            "2590dfe76daf41c4932b0bc0edb1e481",
            "0c1aac8e05874331a854f3a5c17b11a3",
            "d2e32f8055d04ce4a8bfc5d08aadea53",
            "994782b9c1c2470e8cb620857221bb51",
            "612e5c4c968c4914b35b2d94cdd25d03",
            "0aa9a3e366c148f4aa0c2bb54ef75d42"
          ]
        },
        "outputId": "9efff6e6-eb14-4d75-a198-5daffdb251f7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/511M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c504feac51d47f289a9ba19a0b9a501"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForTokenClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n",
            "- This IS expected if you are initializing ElectraForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boLMdjqRvFA8",
        "outputId": "f3cef188-8fab-4b79-a663-aeb2df7135fb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "RBNcn9oQvFF5",
        "outputId": "78e583af-35af-4ff9-dd0f-73ccb3d5afb5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='54635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   23/54635 00:05 < 3:37:16, 4.19 it/s, Epoch 0.00/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         )\n\u001b[0;32m-> 1645\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1976\u001b[0m                             )\n\u001b[1;32m   1977\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1978\u001b[0;31m                             self.accelerator.clip_grad_norm_(\n\u001b[0m\u001b[1;32m   1979\u001b[0m                                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m                                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(self, parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m   2156\u001b[0m                     \u001b[0macc_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_xla_gradients_synced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mfirst_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;34m=\u001b[0m \u001b[0m_group_tensors_by_device_and_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnorm_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mfirst_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;34m=\u001b[0m \u001b[0m_group_tensors_by_device_and_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnorm_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "eJAU275jvFKO",
        "outputId": "3b95af3b-9e36-4424-b609-757a98798295"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18001' max='54635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18001/54635 1:48:53 < 3:41:37, 2.76 it/s, Epoch 1.65/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.347600</td>\n",
              "      <td>0.229978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.215900</td>\n",
              "      <td>0.182514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.182000</td>\n",
              "      <td>0.169995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.171000</td>\n",
              "      <td>0.155971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.161600</td>\n",
              "      <td>0.148856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.148200</td>\n",
              "      <td>0.138977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.148600</td>\n",
              "      <td>0.134349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.143800</td>\n",
              "      <td>0.131404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.142300</td>\n",
              "      <td>0.127040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.134500</td>\n",
              "      <td>0.126455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.132000</td>\n",
              "      <td>0.120538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.110100</td>\n",
              "      <td>0.119461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.106700</td>\n",
              "      <td>0.120201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.110000</td>\n",
              "      <td>0.118696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.107400</td>\n",
              "      <td>0.115921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.104000</td>\n",
              "      <td>0.115880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.103100</td>\n",
              "      <td>0.116491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='471' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [342/342 04:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='54635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   23/54635 00:05 < 3:37:16, 4.19 it/s, Epoch 0.00/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.111767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.11176680028438568}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(test_dataset)\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "S5IrcrcxEH2M",
        "outputId": "0c5ecd5c-567a-44f0-8bed-f6d704a358d4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='54635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   23/54635 00:05 < 3:37:16, 4.19 it/s, Epoch 0.00/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.111767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='342' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [342/342 02:34]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21853, 128, 39) (21853, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)"
      ],
      "metadata": {
        "id": "p_RloNdCEH7Q"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_ner = {i:j for j, i in tag2id.items()}\n",
        "f_label = [i for i, j in tag2id.items()]\n",
        "val_tags_l = [index_to_ner[x] for x in np.ravel(predictions.label_ids).astype(int).tolist()]\n",
        "y_predicted_l = [index_to_ner[x] for x in np.ravel(preds).astype(int).tolist()]"
      ],
      "metadata": {
        "id": "Exrej6TWEH9w"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report"
      ],
      "metadata": {
        "id": "yj6taY6AEH_k"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 추가\n",
        "print(classification_report(val_tags_l, y_predicted_l, labels=f_label))"
      ],
      "metadata": {
        "id": "NIBjHBBG7z8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b887741-285d-4c21-ced9-d2342f8ce16a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       POH_B       0.63      0.58      0.60      3333\n",
            "       CVL_B       0.78      0.81      0.79     51705\n",
            "       FLD_B       0.60      0.44      0.51      2046\n",
            "       FLD_I       0.00      0.00      0.00        29\n",
            "       EVT_I       0.70      0.74      0.72      6233\n",
            "       AFW_B       0.71      0.43      0.53      4589\n",
            "       CVL_I       0.45      0.34      0.39      2798\n",
            "       NUM_B       0.93      0.93      0.93     45374\n",
            "       MAT_I       0.00      0.00      0.00        26\n",
            "       TIM_I       0.84      0.85      0.84       959\n",
            "       ANM_I       0.00      0.00      0.00        30\n",
            "       PER_I       0.69      0.68      0.69      6533\n",
            "       POH_I       0.71      0.62      0.66      5117\n",
            "       TRM_I       0.46      0.38      0.42      2574\n",
            "       TIM_B       0.81      0.80      0.81      2117\n",
            "       ANM_B       0.74      0.68      0.71      4497\n",
            "           O       0.99      0.99      0.99   2450478\n",
            "       DAT_I       0.83      0.92      0.87      5611\n",
            "       DUR_I       0.60      0.77      0.68       681\n",
            "       PNT_B       0.88      0.96      0.91       771\n",
            "       PNT_I       0.92      0.93      0.92       303\n",
            "       MNY_I       0.97      0.99      0.98       948\n",
            "       EVT_B       0.78      0.75      0.76     11622\n",
            "       ORG_I       0.62      0.61      0.61      8988\n",
            "       MNY_B       0.98      0.98      0.98       744\n",
            "       ORG_B       0.84      0.78      0.81     53683\n",
            "       LOC_B       0.68      0.80      0.74     22561\n",
            "       PLT_I       0.00      0.00      0.00         0\n",
            "       MAT_B       0.00      0.00      0.00       213\n",
            "       DAT_B       0.92      0.90      0.91     17646\n",
            "       NUM_I       0.64      0.66      0.65      5294\n",
            "       AFW_I       0.67      0.47      0.55      1975\n",
            "       PLT_B       0.00      0.00      0.00       173\n",
            "       DUR_B       0.67      0.64      0.65       412\n",
            "       PER_B       0.84      0.86      0.85     42838\n",
            "       LOC_I       0.54      0.36      0.43      1661\n",
            "       NOH_B       0.90      0.91      0.91      3807\n",
            "       TRM_B       0.80      0.79      0.79     25492\n",
            "       NOH_I       0.86      0.89      0.87      3323\n",
            "\n",
            "   micro avg       0.97      0.97      0.97   2797184\n",
            "   macro avg       0.64      0.62      0.63   2797184\n",
            "weighted avg       0.97      0.97      0.97   2797184\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('kcelectra_base_new')"
      ],
      "metadata": {
        "id": "IeGUY8DaJp9S"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2tag.values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S71sM9HcLlEZ",
        "outputId": "ff3650eb-e10d-40c3-c59b-49cb8093d0fd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values(['POH_B', 'CVL_B', 'FLD_B', 'FLD_I', 'EVT_I', 'AFW_B', 'CVL_I', 'NUM_B', 'MAT_I', 'TIM_I', 'ANM_I', 'PER_I', 'POH_I', 'TRM_I', 'TIM_B', 'ANM_B', 'O', 'DAT_I', 'DUR_I', 'PNT_B', 'PNT_I', 'MNY_I', 'EVT_B', 'ORG_I', 'MNY_B', 'ORG_B', 'LOC_B', 'PLT_I', 'MAT_B', 'DAT_B', 'NUM_I', 'AFW_I', 'PLT_B', 'DUR_B', 'PER_B', 'LOC_I', 'NOH_B', 'TRM_B', 'NOH_I'])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장한 모델 불러오기\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
        "MODEL_NAME = \"beomi/KcELECTRA-base-v2022\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "tag2id = {'POH_B': 0, 'CVL_B': 1, 'FLD_B': 2, 'FLD_I': 3, 'EVT_I': 4,'AFW_B': 5,'CVL_I': 6,'NUM_B': 7,'MAT_I': 8, 'TIM_I': 9,'ANM_I': 10,'PER_I': 11,'POH_I': 12,\n",
        " 'TRM_I': 13,\n",
        " 'TIM_B': 14,\n",
        " 'ANM_B': 15,\n",
        " 'O': 16,\n",
        " 'DAT_I': 17,\n",
        " 'DUR_I': 18,\n",
        " 'PNT_B': 19,\n",
        " 'PNT_I': 20,\n",
        " 'MNY_I': 21,\n",
        " 'EVT_B': 22,\n",
        " 'ORG_I': 23,\n",
        " 'MNY_B': 24,\n",
        " 'ORG_B': 25,\n",
        " 'LOC_B': 26,\n",
        " 'PLT_I': 27,\n",
        " 'MAT_B': 28,\n",
        " 'DAT_B': 29,\n",
        " 'NUM_I': 30,\n",
        " 'AFW_I': 31,\n",
        " 'PLT_B': 32,\n",
        " 'DUR_B': 33,\n",
        " 'PER_B': 34,\n",
        " 'LOC_I': 35,\n",
        " 'NOH_B': 36,\n",
        " 'TRM_B': 37,\n",
        " 'NOH_I': 38}\n",
        "unique_tags={'POH_B', 'CVL_B', 'FLD_B', 'FLD_I', 'EVT_I', 'AFW_B', 'CVL_I', 'NUM_B', 'MAT_I', 'TIM_I', 'ANM_I', 'PER_I', 'POH_I', 'TRM_I', 'TIM_B', 'ANM_B', 'O', 'DAT_I', 'DUR_I', 'PNT_B', 'PNT_I', 'MNY_I', 'EVT_B', 'ORG_I', 'MNY_B', 'ORG_B', 'LOC_B', 'PLT_I', 'MAT_B', 'DAT_B', 'NUM_I', 'AFW_I', 'PLT_B', 'DUR_B', 'PER_B', 'LOC_I', 'NOH_B', 'TRM_B', 'NOH_I'}\n",
        "id2tag={0: 'POH_B',\n",
        " 1: 'CVL_B',\n",
        " 2: 'FLD_B',\n",
        " 3: 'FLD_I',\n",
        " 4: 'EVT_I',\n",
        " 5: 'AFW_B',\n",
        " 6: 'CVL_I',\n",
        " 7: 'NUM_B',\n",
        " 8: 'MAT_I',\n",
        " 9: 'TIM_I',\n",
        " 10: 'ANM_I',\n",
        " 11: 'PER_I',\n",
        " 12: 'POH_I',\n",
        " 13: 'TRM_I',\n",
        " 14: 'TIM_B',\n",
        " 15: 'ANM_B',\n",
        " 16: 'O',\n",
        " 17: 'DAT_I',\n",
        " 18: 'DUR_I',\n",
        " 19: 'PNT_B',\n",
        " 20: 'PNT_I',\n",
        " 21: 'MNY_I',\n",
        " 22: 'EVT_B',\n",
        " 23: 'ORG_I',\n",
        " 24: 'MNY_B',\n",
        " 25: 'ORG_B',\n",
        " 26: 'LOC_B',\n",
        " 27: 'PLT_I',\n",
        " 28: 'MAT_B',\n",
        " 29: 'DAT_B',\n",
        " 30: 'NUM_I',\n",
        " 31: 'AFW_I',\n",
        " 32: 'PLT_B',\n",
        " 33: 'DUR_B',\n",
        " 34: 'PER_B',\n",
        " 35: 'LOC_I',\n",
        " 36: 'NOH_B',\n",
        " 37: 'TRM_B',\n",
        " 38: 'NOH_I'}\n",
        "pad_token_id = tokenizer.pad_token_id # 0\n",
        "cls_token_id = tokenizer.cls_token_id # 101\n",
        "sep_token_id = tokenizer.sep_token_id # 102\n",
        "pad_token_label_id = tag2id['O']    # tag2id['O']\n",
        "cls_token_label_id = tag2id['O']\n",
        "sep_token_label_id = tag2id['O']\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained('kcelectra_base_new', num_labels=len(unique_tags))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiw4e8yPJsZQ",
        "outputId": "b0bb2512-995b-4cd4-c7da-5e6391e47402"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForTokenClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(54343, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=39, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 토크나이저는 wordPiece tokenizer로 tokenizing 결과를 반환합니다.\n",
        "# 데이터 단위를 음절 단위로 변경했기 때문에, tokenizer도 음절 tokenizer로 변경\n",
        "\n",
        "# berttokenizer를 사용하는데 한국어 vocab이 8000개 정도 밖에 없고 그 안의 한국어들의 거의 음절로 존재\n",
        "# -> 음절 단위 tokenizer를 적용하면 vocab id를 어느 정도 획득할 수 있어 UNK가 별로 없을듯 하다\n",
        "def ner_tokenizer(sent, max_seq_length):\n",
        "    pre_syllable = \"_\"\n",
        "    input_ids = [pad_token_id] * (max_seq_length - 1)\n",
        "    attention_mask = [0] * (max_seq_length - 1)\n",
        "    token_type_ids = [0] * max_seq_length\n",
        "    sent = sent[:max_seq_length-2]\n",
        "\n",
        "    for i, syllable in enumerate(sent):\n",
        "        if syllable == '_':\n",
        "            pre_syllable = syllable\n",
        "        if pre_syllable != \"_\":\n",
        "            syllable = '##' + syllable  # 중간 음절에는 모두 prefix를 붙입니다.\n",
        "            # 우리가 구성한 학습 데이터도 이렇게 구성되었기 때문이라고 함.\n",
        "            # 이순신은 조선 -> [이, ##순, ##신, ##은, 조, ##선]\n",
        "        pre_syllable = syllable\n",
        "\n",
        "        input_ids[i] = (tokenizer.convert_tokens_to_ids(syllable))\n",
        "        attention_mask[i] = 1\n",
        "\n",
        "    input_ids = [cls_token_id] + input_ids\n",
        "    input_ids[len(sent)+1] = sep_token_id\n",
        "    attention_mask = [1] + attention_mask\n",
        "    attention_mask[len(sent)+1] = 1\n",
        "    return {\"input_ids\":input_ids,\n",
        "            \"attention_mask\":attention_mask,\n",
        "            \"token_type_ids\":token_type_ids}"
      ],
      "metadata": {
        "id": "S_lIHQTeJsWX"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ner_inference(text) :\n",
        "\n",
        "    model.eval()\n",
        "    text = text.replace(' ', '_')\n",
        "\n",
        "    predictions , true_labels = [], []\n",
        "\n",
        "    tokenized_sent = ner_tokenizer(text, len(text)+2)\n",
        "    input_ids = torch.tensor(tokenized_sent['input_ids']).unsqueeze(0).to(device)\n",
        "    attention_mask = torch.tensor(tokenized_sent['attention_mask']).unsqueeze(0).to(device)\n",
        "    token_type_ids = torch.tensor(tokenized_sent['token_type_ids']).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids)\n",
        "\n",
        "    logits = outputs['logits']\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = token_type_ids.cpu().numpy()\n",
        "\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "    pred_tags = [list(tag2id.keys())[p_i] for p in predictions for p_i in p]\n",
        "\n",
        "    print('{}\\t{}'.format(\"TOKEN\", \"TAG\"))\n",
        "    print(\"===========\")\n",
        "    # for token, tag in zip(tokenizer.decode(tokenized_sent['input_ids']), pred_tags):\n",
        "    #   print(\"{:^5}\\t{:^5}\".format(token, tag))\n",
        "    for i, tag in enumerate(pred_tags):\n",
        "        print(\"{:^5}\\t{:^5}\".format(tokenizer.convert_ids_to_tokens(tokenized_sent['input_ids'][i]), tag))"
      ],
      "metadata": {
        "id": "2Zl7-l9DMZ8o"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text='모레 10시 반 안과 방문 예정, 시력 물어보기'"
      ],
      "metadata": {
        "id": "BJ9W6DNiMhRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_inference(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7se1iUiJsUu",
        "outputId": "b7f21783-1669-498d-ab9a-f743a759b5e0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOKEN\tTAG\n",
            "===========\n",
            "[CLS]\t  O  \n",
            "  1  \tDUR_B\n",
            " ##2 \tDUR_B\n",
            "[UNK]\tDUR_I\n",
            " ##2 \tDUR_I\n",
            " ##0 \tDUR_I\n",
            "[UNK]\tDUR_I\n",
            " ##1 \tDUR_I\n",
            " ##2 \tDUR_I\n",
            "[UNK]\tDUR_I\n",
            " ##2 \tDUR_I\n",
            " ##5 \tDUR_I\n",
            " ##일 \tDUR_I\n",
            " ##은 \t  O  \n",
            "  _  \t  O  \n",
            "  크  \tPOH_B\n",
            " ##리 \tPOH_B\n",
            " ##스 \tPOH_B\n",
            " ##마 \tPOH_B\n",
            " ##스 \tPOH_B\n",
            "  _  \tPOH_I\n",
            "  파  \tPOH_I\n",
            " ##티 \t  O  \n",
            " ##를 \t  O  \n",
            "  _  \t  O  \n",
            "  준  \t  O  \n",
            " ##비 \t  O  \n",
            " ##할 \t  O  \n",
            " ##거 \t  O  \n",
            " ##야 \t  O  \n",
            "[SEP]\t  O  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rg_xQwCBJsQD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}